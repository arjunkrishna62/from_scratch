{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2925d0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import tiktoken\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0a6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try brew install\n",
      "\u001b[31m   \u001b[0m xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a Python library that isn't in Homebrew,\n",
      "\u001b[31m   \u001b[0m use a virtual environment:\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m python3 -m venv path/to/venv\n",
      "\u001b[31m   \u001b[0m source path/to/venv/bin/activate\n",
      "\u001b[31m   \u001b[0m python3 -m pip install xyz\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a Python application that isn't in Homebrew,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. You can install pipx with\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m brew install pipx\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m You may restore the old behavior of pip by passing\n",
      "\u001b[31m   \u001b[0m the '--break-system-packages' flag to pip, or by adding\n",
      "\u001b[31m   \u001b[0m 'break-system-packages = true' to your pip.conf file. The latter\n",
      "\u001b[31m   \u001b[0m will permanently disable this error.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you disable this error, we STRONGLY recommend that you additionally\n",
      "\u001b[31m   \u001b[0m pass the '--user' flag to pip, or set 'user = true' in your pip.conf\n",
      "\u001b[31m   \u001b[0m file. Failure to do this can result in a broken Homebrew installation.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m Read more about this behavior here: <https://peps.python.org/pep-0668/>\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7feba8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 62,186 tokens\n",
      "val has 6,902 tokens\n"
     ]
    }
   ],
   "source": [
    "source_file = '/Users/arjunkrishna/Desktop/tfr_llm/the-hundred-page-machine-learning--.txt'\n",
    "\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    raw_data = f.read()\n",
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_data)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "\n",
    "# split into 90/10\n",
    "n = len(preprocessed)\n",
    "train_data = preprocessed[:int(n*0.9)]\n",
    "val_data = preprocessed[int(n*0.9):]\n",
    "\n",
    "train_text = \" \".join(train_data) #'text': 'list' object cannot be converted to 'PyString' \n",
    "val_text = \" \".join(val_data) # so we romove the list by using join\n",
    "\n",
    "# tokenize using gpt2 \n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "train_ids = enc.encode_ordinary(train_text)\n",
    "val_ids = enc.encode_ordinary(val_text)\n",
    "\n",
    "torch.save(torch.tensor(train_ids), 'train.pt')\n",
    "torch.save(torch.tensor(val_ids), 'train.pt')\n",
    "\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "print(f\"val has {len(val_ids):,} tokens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69499e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import dataset, dataloader\n",
    "class DatasetV1(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = enc.encode(txt)\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bd20b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4452ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "[[0.43, 0.15, 0.89], # your     (x^1)\n",
    " [0.55, 0.87, 0.66], # journey  (x^2)\n",
    " [0.55, 0.87, 0.66], # starts   (x^3)\n",
    " [0.22, 0.58, 0.33], # with     (x^4)\n",
    " [0.77, 0.25, 0.10], # one      (x^5)\n",
    " [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e587a5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.4300, 0.1500, 0.8900])\n",
      "1 tensor([0.5500, 0.8700, 0.6600])\n",
      "2 tensor([0.5500, 0.8700, 0.6600])\n",
      "3 tensor([0.2200, 0.5800, 0.3300])\n",
      "4 tensor([0.7700, 0.2500, 0.1000])\n",
      "5 tensor([0.0500, 0.8000, 0.5500])\n",
      "tensor([0.9544, 1.4950, 1.4950, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    print(i , x_i)\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c089b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1450, 0.2272, 0.2272, 0.1282, 0.1074, 0.1651])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2_tmp = attn_scores_2 / attn_scores_2.sum() # normalizing the attention scores \n",
    "print(\"Attention weights:\", attn_weights_2_tmp)\n",
    "print(\"Sum:\", attn_weights_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e2e1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1379, 0.2368, 0.2368, 0.1234, 0.1077, 0.1574])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim=0)\n",
    "attn_weights_2_naive = softmax_naive(attn_scores_2)\n",
    "print(\"Attention weights:\", attn_weights_2_naive)\n",
    "print(\"Sum:\", attn_weights_2_naive.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0336aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1379, 0.2368, 0.2368, 0.1234, 0.1077, 0.1574])\n",
      "Sum: tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86e2c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4377, 0.6571, 0.5734])\n"
     ]
    }
   ],
   "source": [
    "# calculating context vectore with computed normalized attention weights\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i,x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i]*x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcc22abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9544, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4950, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9544, 1.4950, 1.4950, 0.8434, 0.7070, 1.0865],\n",
      "        [0.4753, 0.8434, 0.8434, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7070, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0865, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = torch.empty(6, 6) # attention scores\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8acdaf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9544, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4950, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9544, 1.4950, 1.4950, 0.8434, 0.7070, 1.0865],\n",
      "        [0.4753, 0.8434, 0.8434, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7070, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0865, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T # for loops are generally slow so we use matrix multplication\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "759eb240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2093, 0.2001, 0.2001, 0.1239, 0.1218, 0.1448],\n",
      "        [0.1379, 0.2368, 0.2368, 0.1234, 0.1077, 0.1574],\n",
      "        [0.1379, 0.2368, 0.2368, 0.1234, 0.1077, 0.1574],\n",
      "        [0.1431, 0.2068, 0.2068, 0.1458, 0.1259, 0.1716],\n",
      "        [0.1529, 0.1962, 0.1962, 0.1369, 0.1882, 0.1297],\n",
      "        [0.1377, 0.2171, 0.2171, 0.1413, 0.0983, 0.1885]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1) # normalize  so that the values in each row sum to 1\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1951b14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 sum: 1.0\n",
      "All row sums: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"Row 2 sum:\", row_2_sum)\n",
    "print(\"All row sums:\", attn_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc6698f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4384, 0.5977, 0.5831],\n",
      "        [0.4377, 0.6571, 0.5734],\n",
      "        [0.4377, 0.6571, 0.5734],\n",
      "        [0.4266, 0.6346, 0.5554],\n",
      "        [0.4630, 0.5945, 0.5303],\n",
      "        [0.4142, 0.6558, 0.5693]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs # use attn_weights to compute all context vectors via mtx multplication\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a3a1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous 2nd context vector: tensor([0.4377, 0.6571, 0.5734])\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous 2nd context vector:\", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14e128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
